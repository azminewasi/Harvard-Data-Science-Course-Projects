{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python for Research Homework: Week 3, Case Study 2\n",
    "\n",
    "In this case study, we will find and plot the distribution of word frequencies for each translation of Hamlet.  Perhaps the distribution of word frequencies of Hamlet depends on the translation --- let's find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT THIS CODE!\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def count_words_fast(text):\n",
    "    text = text.lower()\n",
    "    skips = [\".\", \",\", \";\", \":\", \"'\", '\"', \"\\n\", \"!\", \"?\", \"(\", \")\"]\n",
    "    for ch in skips:\n",
    "        text = text.replace(ch, \"\")\n",
    "    word_counts = Counter(text.split(\" \"))\n",
    "    return word_counts\n",
    "\n",
    "def word_stats(word_counts):\n",
    "    num_unique = len(word_counts)\n",
    "    counts = word_counts.values()\n",
    "    return (num_unique, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 \n",
    "\n",
    "In this case study, we will find and visualize summary statistics of the text of different translations of Hamlet. For this case study, functions `count_words_fast` and `word_stats` are already defined as in the Case 2 Videos (Videos 3.2.x).\n",
    "\n",
    "#### Instructions \n",
    "- Read in the data as a pandas dataframe using `pd.read_csv`. Use the `index_col` argument to set the first column in the csv file as the index for the dataframe. The data can be found at https://courses.edx.org/asset-v1:HarvardX+PH526x+2T2019+type@asset+block@hamlets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     language                                               text\n1     English  The Tragedie of Hamlet\\n                      ...\n2      German  Hamlet, Prinz von D채nnemark.\\n                ...\n3  Portuguese  HAMLET\\n                             DRAMA EM ...\n"
     ]
    }
   ],
   "source": [
    "hamlets = pd.read_csv(\"https://courses.edx.org/asset-v1:HarvardX+PH526x+2T2019+type@asset+block@hamlets.csv\",index_col=0)\n",
    "print(hamlets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 \n",
    "\n",
    "In this exercise, we will summarize the text for a single translation of Hamlet in a `pandas` dataframe. \n",
    "\n",
    "#### Instructions\n",
    "- Find the dictionary of word frequency in `text` by calling `count_words_fast()`. Store this as `counted_text`.\n",
    "- Create a `pandas` dataframe named `data`.\n",
    "- Using `counted_text`, define two columns in data:\n",
    "    - `word`, consisting of each unique word in text.\n",
    "    - `count`, consisting of the number of times each word in `word` is included in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 word  count\n0              hamlet    210\n1               prinz     16\n2                 von    212\n3           d채nnemark     14\n4                      67223\n...               ...    ...\n7476        tradeused      1\n7477            sales      1\n7478         hardware      1\n7479          related      1\n7480  permission]*end      1\n\n[7481 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "language, text = hamlets.iloc[1]\n",
    "counted_text=count_words_fast(text)\n",
    "datas=(dict(counted_text))\n",
    "data=pd.DataFrame(list(datas.items()),columns=('word','count'))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "In this exercise, we will continue to define summary statistics for a single translation of Hamlet. \n",
    "\n",
    "#### Instructions\n",
    "- Add a column to data named `length`, defined as the length of each word.\n",
    "- Add another column named `frequency`, which is defined as follows for each word in `data`:\n",
    "    - If `count > 10`, `frequency` is \"frequent\".\n",
    "    - If `1 < count <= 10`, `frequency` is \"infrequent\".\n",
    "    - If `count == 1`, `frequency` is \"unique\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 word  count  length\n0              hamlet    210       6\n1               prinz     16       5\n2                 von    212       3\n3           d채nnemark     14       9\n4                      67223       0\n...               ...    ...     ...\n7476        tradeused      1       9\n7477            sales      1       5\n7478         hardware      1       8\n7479          related      1       7\n7480  permission]*end      1      15\n\n[7481 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data['length']=data.apply(lambda row: len(row.word), axis=1)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 word  count  length frequency\n0              hamlet    210       6  frequent\n1               prinz     16       5  frequent\n2                 von    212       3  frequent\n3           d채nnemark     14       9  frequent\n4                      67223       0  frequent\n...               ...    ...     ...       ...\n7476        tradeused      1       9    unique\n7477            sales      1       5    unique\n7478         hardware      1       8    unique\n7479          related      1       7    unique\n7480  permission]*end      1      15    unique\n\n[7481 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "conditions = [\n",
    "    (data['count'] == 1),\n",
    "    (data['count'] > 1) & (data['count'] <= 10),\n",
    "    (data['count'] > 10)\n",
    "    ]\n",
    "values = ['unique', 'infrequent', 'frequent']\n",
    "data['frequency'] = np.select(conditions, values)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            word  count  length\nfrequency                      \nfrequent     303    303     303\ninfrequent  1596   1596    1596\nunique      5582   5582    5582\n"
     ]
    }
   ],
   "source": [
    "Group=data.groupby('frequency').agg(np.size)\n",
    "print(Group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 count    length\nfrequency                       \nfrequent    271.590759  4.528053\ninfrequent    3.383459  6.481830\nunique        1.000000  9.006987\n"
     ]
    }
   ],
   "source": [
    "Group=data.groupby('frequency').agg(np.mean)\n",
    "print(Group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "In this exercise, we will summarize the statistics in data into a smaller pandas dataframe. \n",
    "\n",
    "#### Instructions \n",
    "- Create a `pandas` dataframe named `sub_data` including the following columns:\n",
    "    - `language`, which is the language of the text (defined in Exercise 2).\n",
    "    - `frequency`, which is a list containing the strings \"frequent\", \"infrequent\", and \"unique\".\n",
    "    - `mean_word_length`, which is the mean word length of each value in frequency.\n",
    "    - `num_words`, which is the total number of words in each frequency category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 count    length\nfrequency                       \nfrequent    203.182663  4.371517\ninfrequent    3.509015  5.825243\nunique        1.000000  7.005675\n"
     ]
    }
   ],
   "source": [
    "Group=data.groupby('frequency').agg(np.mean)\n",
    "print(Group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(language, text):\n",
    "    counted_text = count_words_fast(text)\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        \"word\": list(counted_text.keys()),\n",
    "        \"count\": list(counted_text.values())\n",
    "    })\n",
    "    \n",
    "    data.loc[data[\"count\"] > 10,  \"frequency\"] = \"frequent\"\n",
    "    data.loc[data[\"count\"] <= 10, \"frequency\"] = \"infrequent\"\n",
    "    data.loc[data[\"count\"] == 1,  \"frequency\"] = \"unique\"\n",
    "    \n",
    "    data[\"length\"] = data[\"word\"].apply(len)\n",
    "    \n",
    "    sub_data = pd.DataFrame({\n",
    "        \"language\": language,\n",
    "        \"frequency\": [\"frequent\",\"infrequent\",\"unique\"],\n",
    "        \"mean_word_length\": data.groupby(by = \"frequency\")[\"length\"].mean(),\n",
    "        \"num_words\": data.groupby(by = \"frequency\").size()\n",
    "    })\n",
    "    \n",
    "    return(sub_data)\n",
    "    \n",
    "# write your code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"Portuguese\": \"green\", \"English\": \"blue\", \"German\": \"red\"}\n",
    "markers = {\"frequent\": \"o\",\"infrequent\": \"s\", \"unique\": \"^\"}\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(grouped_data.shape[0]):\n",
    "    row = grouped_data.iloc[i]\n",
    "    plt.plot(row.mean_word_length, row.num_words,\n",
    "        marker=markers[row.frequency],\n",
    "        color = colors[row.language],\n",
    "        markersize = 10\n",
    "    )\n",
    "\n",
    "color_legend = []\n",
    "marker_legend = []\n",
    "for color in colors:\n",
    "    color_legend.append(\n",
    "        plt.plot([], [],\n",
    "        color=colors[color],\n",
    "        marker=\"o\",\n",
    "        label = color, markersize = 10, linestyle=\"None\")\n",
    "    )\n",
    "for marker in markers:\n",
    "    marker_legend.append(\n",
    "        plt.plot([], [],\n",
    "        color=\"k\",\n",
    "        marker=markers[marker],\n",
    "        label = marker, markersize = 10, linestyle=\"None\")\n",
    "    )\n",
    "plt.legend(numpoints=1, loc = \"upper left\")\n",
    "\n",
    "plt.xlabel(\"Mean Word Length\")\n",
    "plt.ylabel(\"Number of Words\")\n",
    "# write your code to display the plot here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd05d04c838d62abe92b3403c4401110917c05c57a4d727a149b38b15916ebf0092",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}